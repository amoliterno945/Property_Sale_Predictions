{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from itertools import compress\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "import random\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tx=\"asset_transaction_history.csv\"\n",
    "assets=\"assets.csv\"\n",
    "clients=\"clients.csv\"\n",
    "deals=\"deals2.csv\"\n",
    "\n",
    "assets=pd.read_csv(assets)\n",
    "clients=pd.read_csv(clients)\n",
    "tx=pd.read_csv(tx)\n",
    "deals=pd.read_csv(deals)\n",
    "\n",
    "tx.columns=list(tx)[:-1]+[\"AssetID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NA_randreplace(df):\n",
    "    #Replaces NAs IN-PLACE by random selection\n",
    "    for i in list(df):\n",
    "        rows=pd.isnull(assets.loc[:,i]) #NA detector\n",
    "        index=rows.loc[rows==True].index #filter for NAs\n",
    "        Nan_Index=assets.loc[index,i].index #Targeted rows for replacement\n",
    "        \n",
    "        k=df.loc[:,i].isna().sum() #number of NAs to fill\n",
    "        not_nas=list(df.loc[df.loc[:,i].notna(),i]) #Create Not-NAs pool to sample\n",
    "        fill_list=random.choices(not_nas,k=k) #randomly select\n",
    "        \n",
    "        df.loc[Nan_Index,i]=fill_list #replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asset columns\n",
    "screen1 =['AssetID',\\\n",
    "          'City',\\\n",
    "          'State',\\\n",
    "          'CountryID',\\\n",
    "          'PropertyType',\\\n",
    "          'PropertyTypeGroup',\\\n",
    "          'YearBuilt',\\\n",
    "          'AssetLatitude',\\\n",
    "          'AssetLongitude',\\\n",
    "          'LandAreaInAcres',\\\n",
    "          'NumberofFloors',\\\n",
    "          'NumberofBuildings',\\\n",
    "          'YearRenovated',\\\n",
    "          'Size_Acres',\\\n",
    "          'Lat_city',\\\n",
    "          'Long_city',\\\n",
    "          'IsGateway',\\\n",
    "          'Region',\\\n",
    "          'Size_Sqft',\\\n",
    "          'Size_Units',\\\n",
    "          'Class',\\\n",
    "          'Market_name']\n",
    "\n",
    "\n",
    "#Client columns\n",
    "screen2 = ['ClientID',\\\n",
    " 'Client_IsForeign',\\\n",
    " 'Client_InvestorType',\\\n",
    " 'Client_LenderBook',\\\n",
    " 'Client_BuyerBook',\\\n",
    " 'Client_SFBook',\\\n",
    " 'Client_NSBook',\\\n",
    " 'Client_HFFSBook']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets=assets.loc[assets.CountryID==1,screen1]\n",
    "clients=clients.loc[:,screen2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx=tx.merge(assets,on=\"AssetID\")\n",
    "tx=tx.merge(deals.loc[deals.Stage==\"Completed and Paid\",],on=\"DealID\")\n",
    "tx=tx.merge(clients,on=\"ClientID\")\n",
    "tx.loc[:,\"AccountingDate\"]=[datetime.strptime(x, '%m/%d/%Y') for x in tx.loc[:,\"AccountingDate\"]]\n",
    "tx.sort_values(by='AccountingDate',ascending=False,inplace=True)\n",
    "tx.index=range(len(tx))\n",
    "tx[\"y\"] = 0 #create column\n",
    "assets[\"y\"] = 0 #create column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssetID</th>\n",
       "      <th>CountryID</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>AssetLatitude</th>\n",
       "      <th>AssetLongitude</th>\n",
       "      <th>LandAreaInAcres</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>YearRenovated</th>\n",
       "      <th>Size_Acres</th>\n",
       "      <th>Lat_city</th>\n",
       "      <th>Long_city</th>\n",
       "      <th>IsGateway</th>\n",
       "      <th>Size_Sqft</th>\n",
       "      <th>Size_Units</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>183945.0</td>\n",
       "      <td>183945.0</td>\n",
       "      <td>142781.0</td>\n",
       "      <td>181997.0</td>\n",
       "      <td>181997.0</td>\n",
       "      <td>97778.0</td>\n",
       "      <td>73421.0</td>\n",
       "      <td>32190.0</td>\n",
       "      <td>112844.0</td>\n",
       "      <td>171388.0</td>\n",
       "      <td>171388.0</td>\n",
       "      <td>183945.0</td>\n",
       "      <td>1.483650e+05</td>\n",
       "      <td>65440.0</td>\n",
       "      <td>183945.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>96566.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1981.9</td>\n",
       "      <td>36.6</td>\n",
       "      <td>-93.6</td>\n",
       "      <td>700.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2000.9</td>\n",
       "      <td>1069.9</td>\n",
       "      <td>36.5</td>\n",
       "      <td>-94.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.747770e+05</td>\n",
       "      <td>1169.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60291.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>17.9</td>\n",
       "      <td>21817.6</td>\n",
       "      <td>14.9</td>\n",
       "      <td>512.5</td>\n",
       "      <td>33672.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.046154e+07</td>\n",
       "      <td>18681.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-36.9</td>\n",
       "      <td>-159.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>-159.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45170.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-111.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>32.9</td>\n",
       "      <td>-111.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.895800e+04</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>89720.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>-88.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>36.7</td>\n",
       "      <td>-89.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.044500e+05</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>152258.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-80.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.205830e+05</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>205293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>64.9</td>\n",
       "      <td>150.8</td>\n",
       "      <td>2246389.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>93912.0</td>\n",
       "      <td>6594548.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>-67.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.979925e+09</td>\n",
       "      <td>1837074.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AssetID  CountryID  YearBuilt  AssetLatitude  AssetLongitude  \\\n",
       "count  183945.0   183945.0   142781.0       181997.0        181997.0   \n",
       "mean    96566.8        1.0     1981.9           36.6           -93.6   \n",
       "std     60291.7        0.0       27.4            5.3            17.9   \n",
       "min         1.0        1.0     -200.0          -36.9          -159.7   \n",
       "25%     45170.0        1.0     1972.0           33.0          -111.9   \n",
       "50%     89720.0        1.0     1987.0           37.4           -88.0   \n",
       "75%    152258.0        1.0     2000.0           40.7           -79.0   \n",
       "max    205293.0        1.0     2024.0           64.9           150.8   \n",
       "\n",
       "       LandAreaInAcres  NumberofBuildings  YearRenovated  Size_Acres  \\\n",
       "count          97778.0            73421.0        32190.0    112844.0   \n",
       "mean             700.6                3.7         2000.9      1069.9   \n",
       "std            21817.6               14.9          512.5     33672.3   \n",
       "min               -1.0                0.0          223.0        -1.0   \n",
       "25%                1.6                1.0         1992.0         1.7   \n",
       "50%                5.0                1.0         2001.0         5.1   \n",
       "75%               12.0                2.0         2006.0        12.4   \n",
       "max          2246389.0             1993.0        93912.0   6594548.0   \n",
       "\n",
       "       Lat_city  Long_city  IsGateway     Size_Sqft  Size_Units         y  \n",
       "count  171388.0   171388.0   183945.0  1.483650e+05     65440.0  183945.0  \n",
       "mean       36.5      -94.3        0.2  4.747770e+05      1169.8       0.0  \n",
       "std         5.3       17.2        0.4  2.046154e+07     18681.0       0.0  \n",
       "min        19.6     -159.7        0.0  0.000000e+00         0.0       0.0  \n",
       "25%        32.9     -111.9        0.0  4.895800e+04        81.0       0.0  \n",
       "50%        36.7      -89.6        0.0  1.044500e+05       151.0       0.0  \n",
       "75%        40.7      -80.1        0.0  2.205830e+05       265.0       0.0  \n",
       "max        64.8      -67.8        1.0  3.979925e+09   1837074.0       0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(assets.describe(),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean unreasonable outliers\n",
    "assets.loc[assets.YearBuilt<1700,\"YearBuilt\"]=np.nan #YearBuilt before 1700\n",
    "assets.loc[assets.LandAreaInAcres<0,\"LandAreaInAcres\"]=np.nan #-1 acres\n",
    "assets.loc[assets.Size_Acres<0,\"Size_Acres\"]=np.nan\n",
    "assets.loc[assets.YearRenovated\t<1900,\"YearRenovated\"]=np.nan #unreasonable years\n",
    "assets.loc[assets.YearRenovated\t>2025,\"YearRenovated\"]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique properties listed in asset_transactions:  8229\n",
      "unique properties listed in assets:  177120\n",
      "Assets represented in asset_transactions ONLY:  0\n",
      "Assets represented in assets ONLY:  168891\n"
     ]
    }
   ],
   "source": [
    "transactions=np.unique(tx.AssetID) #8229\n",
    "assset=np.unique(assets.AssetID) #177120\n",
    "\n",
    "print(\"unique properties listed in asset_transactions: \",len(transactions))\n",
    "print(\"unique properties listed in assets: \",len(assset))\n",
    "print(\"Assets represented in asset_transactions ONLY: \",len([i for i in transactions if i not in assset])) #NO asset IDs are in tx alone\n",
    "print(\"Assets represented in assets ONLY: \",len([i for i in assset if i not in transactions])) #168891/177120 or ~11k in assets alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables dropped: \n",
      " ['LandAreaInAcres', 'NumberofFloors', 'NumberofBuildings', 'YearRenovated', 'Size_Acres', 'Size_Units', 'Class'] \n",
      "\n",
      "Current NAs %: \n",
      " AssetID              0.000\n",
      "City                 0.000\n",
      "State                0.000\n",
      "CountryID            0.000\n",
      "PropertyType         0.000\n",
      "PropertyTypeGroup    0.026\n",
      "YearBuilt            0.224\n",
      "AssetLatitude        0.011\n",
      "AssetLongitude       0.011\n",
      "Lat_city             0.068\n",
      "Long_city            0.068\n",
      "IsGateway            0.000\n",
      "Region               0.001\n",
      "Size_Sqft            0.193\n",
      "Market_name          0.037\n",
      "y                    0.000\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NA Analysis\n",
    "\n",
    "threshold=.25\n",
    "\n",
    "#Drop predictors which cannot be well imputed (i.e. too many NAs!)\n",
    "screen_hiNA=assets.columns.where(assets.isnull().sum()/len(assets)>threshold)\n",
    "screen_hiNA=list(screen_hiNA[~screen_hiNA.isnull()])\n",
    "print(\"Variables dropped:\",\"\\n\",screen_hiNA,\"\\n\")\n",
    "\n",
    "assets=assets.drop(screen_hiNA,axis=1)\n",
    "\n",
    "print(\"Current NAs %:\",\"\\n\",round(assets.isnull().sum()/len(assets),3),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Nas 117318 \n",
      "\n",
      "Nas remaining 0\n"
     ]
    }
   ],
   "source": [
    "#Imputation: random selection\n",
    "\n",
    "print(\"Current Nas\",np.sum(assets.isnull().sum()),\"\\n\")\n",
    "\n",
    "NA_randreplace(assets)\n",
    "            \n",
    "print(\"Nas remaining\",np.sum(assets.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split & Encode\n",
    "\n",
    "#Train: start-EOY2017\n",
    "#Test: 2018\n",
    "train_threshold=np.datetime64('2018-01-01')\n",
    "test_threshold=np.datetime64('2019-01-01')\n",
    "tx.loc[tx.loc[:,\"AccountingDate\"]>train_threshold,'y']=1 #Set tx's y values based on threshold date\n",
    "\n",
    "#Transfer values to Assets\n",
    "Sold_IDs=list(tx.loc[tx.loc[:,\"y\"]>0,'AssetID']) #Asset IDs of y=1 properties\n",
    "for i in Sold_IDs:\n",
    "    assets.loc[assets.AssetID ==i,\"y\"] =1\n",
    "\n",
    "    \n",
    "\n",
    "#Split train and test based on date\n",
    "filter_test=tx.loc[:,\"AccountingDate\"]>=test_threshold\n",
    "IDs_test=tx.loc[filter_test,\"AssetID\"]\n",
    "test=assets.loc[assets.AssetID.isin(IDs_test),:] #contains only recent properties sold (only recent y=1's)\n",
    "#...Rest are train...\n",
    "train=assets.loc[~assets.AssetID.isin(IDs_test),:] #All tx's BEFORE test threshold are train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete constructing test set by adding rest of properties (y=0's)\n",
    "tx.loc[tx.loc[:,\"AccountingDate\"]<test_threshold,'y']=0 #zero out y's before test threshold date\n",
    "assets2=assets.copy()\n",
    "assets2.loc[:,\"y\"] =0 #zero out y's \n",
    "Sold_IDs=list(tx.loc[tx.loc[:,\"y\"]>0,'AssetID']) #Collect IDs of properties sold (y=1)\n",
    "rest=assets2.loc[~assets.AssetID.isin(Sold_IDs),:] #filter out y=1's\n",
    "test=pd.concat((test,rest),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183945, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183873, 16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape #excludes test threshold samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183945, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape #includes all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train post-codified number of columns:  376\n"
     ]
    }
   ],
   "source": [
    "#ENCODE\n",
    "#Drop non-predictor columns\n",
    "asides=['AssetID','City','CountryID']\n",
    "train=train.drop(asides,axis=1)\n",
    "\n",
    "train=pd.get_dummies(train)\n",
    "\n",
    "print(\"train post-codified number of columns: \",len(list(train)))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train into train + validate\n",
    "train_1=train.loc[train.y==1,:]\n",
    "train_0=train.loc[train.y==0,:]\n",
    "\n",
    "#Due to imbalanced dataset, we split y=1 and y=0 BEFORE upsampling\n",
    "train_1, val_1 = train_test_split(train_1, test_size = 0.30, random_state = 43)\n",
    "train_0, val_0 = train_test_split(train_0, test_size = 0.30, random_state = 43)\n",
    "\n",
    "val=pd.concat((val_1,val_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before upsampling, y=1:  758\n",
      "Before upsampling,y=0:  127953 \n",
      "\n",
      "After upsampling,y=1:  127953\n",
      "After upsampling,y=0:  127953 \n",
      "\n",
      "Total upsampled train length:  255906\n"
     ]
    }
   ],
   "source": [
    "#Upsampling train - targeting a 50/50 split between y=1 and y=0\n",
    "\n",
    "#Assess imbalance\n",
    "print(\"Before upsampling, y=1: \",len(train_1))\n",
    "print(\"Before upsampling,y=0: \",len(train_0),\"\\n\")\n",
    "\n",
    "#Upsample y=1 to match count of y=0 using random selection\n",
    "train_1_indexes = np.random.choice(train_1.index, size=len(train_0)-len(train_1), replace=True)\n",
    "train_1_up=train_1.loc[train_1_indexes,:]\n",
    "train_1=pd.concat((train_1,train_1_up))\n",
    "\n",
    "print(\"After upsampling,y=1: \",len(train_1))\n",
    "print(\"After upsampling,y=0: \",len(train_0),\"\\n\")\n",
    "\n",
    "train=pd.concat((train_1,train_0))\n",
    "\n",
    "print(\"Total upsampled train length: \",len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictors\n",
    "x_train=train.drop(columns='y')\n",
    "x_val=val.drop(columns='y')\n",
    "\n",
    "#Target\n",
    "y_train = train.loc[:,\"y\"]\n",
    "y_val= val.loc[:,\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data 0-1\n",
    "\n",
    "#Save column names\n",
    "cols=list(x_train)\n",
    "\n",
    "# #Scale the data\n",
    "std_scale = MinMaxScaler().fit(x_train)\n",
    "x_train = std_scale.transform(x_train) \n",
    "x_val = std_scale.transform(x_val) \n",
    "\n",
    "#Return to pandas dataframe from numpy array\n",
    "x_train=pd.DataFrame(x_train)\n",
    "x_train.columns=cols\n",
    "x_val=pd.DataFrame(x_val)\n",
    "x_val.columns=cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7017264151680696\n",
      "Validation accuracy:  0.6626481998477213 \n",
      "\n",
      "[[36324 18513]\n",
      " [   96   229]] \n",
      "\n",
      "ROC AUC score\n",
      "0.749363442145323 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-4c0c898130c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# #CROSS VALIDATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: %0.2f (+/- %0.2f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logit=LogisticRegression(penalty='l2', \n",
    "                         dual=False, \n",
    "                         tol=0.0001, \n",
    "                         C=1.0, \n",
    "                         fit_intercept=True, \n",
    "                         intercept_scaling=1, \n",
    "                         class_weight=None, \n",
    "                         random_state=None, \n",
    "                         solver='liblinear', \n",
    "                         max_iter=100, \n",
    "                         multi_class='ovr', \n",
    "                         verbose=0, \n",
    "                         warm_start=False, \n",
    "                         n_jobs=1)\n",
    "\n",
    "logit.fit(x_train,y_train)\n",
    "print(\"Train accuracy: \",logit.score(x_train,y_train))\n",
    "print(\"Validation accuracy: \",logit.score(x_val,y_val),\"\\n\")\n",
    "pred=logit.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred),\"\\n\")\n",
    "\n",
    "\n",
    "probs=logit.predict_proba(x_val)[:,1] #SCREEN FOR PREDICTION OF y=1 PROBS\n",
    "print(\"ROC AUC score\")\n",
    "print(roc_auc_score(y_val, probs),\"\\n\")\n",
    "\n",
    "# #CROSS VALIDATION\n",
    "scores = cross_val_score(logit, x_train, y_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] max_depth=10, max_features=10, random_state=11 ..................\n",
      "[CV] max_depth=10, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=10, random_state=11, score=0.6702106067818389, total=   1.6s\n",
      "[CV]  max_depth=10, max_features=10, random_state=11, score=0.6417655618101069, total=   1.6s\n",
      "[CV] max_depth=10, max_features=10, random_state=11 ..................\n",
      "[CV] max_depth=10, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=10, random_state=11, score=0.6406375555327567, total=   1.7s\n",
      "[CV] max_depth=10, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=10, random_state=11, score=0.6528997564473349, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  60 | elapsed:   10.7s remaining:  2.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=10, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=10, random_state=11, score=0.6696035271385837, total=   1.6s\n",
      "[CV] max_depth=10, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=25, random_state=11, score=0.7229719244416152, total=   1.9s\n",
      "[CV] max_depth=10, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=25, random_state=11, score=0.7341163701781496, total=   1.7s\n",
      "[CV] max_depth=10, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=25, random_state=11, score=0.7057672620959864, total=   1.7s\n",
      "[CV] max_depth=10, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=25, random_state=11, score=0.6993521764818439, total=   1.7s\n",
      "[CV] max_depth=10, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=25, random_state=11, score=0.7213684891198431, total=   1.9s\n",
      "[CV] max_depth=10, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=50, random_state=11, score=0.7285327772409022, total=   2.2s\n",
      "[CV] max_depth=10, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=50, random_state=11, score=0.762449372730339, total=   2.2s\n",
      "[CV] max_depth=10, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=50, random_state=11, score=0.7536320222345763, total=   2.1s\n",
      "[CV] max_depth=10, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=50, random_state=11, score=0.7878647567275525, total=   2.4s\n",
      "[CV] max_depth=10, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=10, max_features=50, random_state=11, score=0.7305057424767667, total=   2.3s\n",
      "[CV] max_depth=10, max_features=150, random_state=11 .................\n",
      "[CV] max_depth=10, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=10, max_features=150, random_state=11, score=0.8362663311581799, total=   4.4s\n",
      "[CV] max_depth=10, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=10, max_features=150, random_state=11, score=0.8109308406768583, total=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 out of  60 | elapsed:   35.9s remaining:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=10, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=10, max_features=150, random_state=11, score=0.8066991701278108, total=   3.8s\n",
      "[CV] max_depth=25, max_features=10, random_state=11 ..................\n",
      "[CV] max_depth=25, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=10, max_features=150, random_state=11, score=0.8230892278682644, total=   4.0s\n",
      "[CV]  max_depth=10, max_features=150, random_state=11, score=0.8323221209620979, total=   3.6s\n",
      "[CV]  max_depth=25, max_features=10, random_state=11, score=0.9124823852112307, total=   2.2s\n",
      "[CV] max_depth=25, max_features=10, random_state=11 ..................\n",
      "[CV] max_depth=25, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=10, random_state=11, score=0.9176490048704146, total=   2.3s\n",
      "[CV]  max_depth=25, max_features=10, random_state=11, score=0.9016129428305174, total=   2.3s\n",
      "[CV] max_depth=25, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=10, random_state=11, score=0.9073075320826312, total=   2.2s\n",
      "[CV] max_depth=25, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=10, random_state=11, score=0.9068071015247658, total=   2.2s\n",
      "[CV] max_depth=25, max_features=25, random_state=11 ..................\n",
      "[CV] max_depth=25, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=25, random_state=11, score=0.9605515722042761, total=   2.5s\n",
      "[CV] max_depth=25, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=25, random_state=11, score=0.9381368033598437, total=   2.6s\n",
      "[CV] max_depth=25, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=25, random_state=11, score=0.9492483631234893, total=   2.6s\n",
      "[CV] max_depth=25, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=25, random_state=11, score=0.9301631966252937, total=   2.6s\n",
      "[CV] max_depth=25, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=25, random_state=11, score=0.9507313780096482, total=   2.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  60 | elapsed:   57.0s remaining:   57.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=25, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=50, random_state=11, score=0.9821694719496875, total=   3.3s\n",
      "[CV] max_depth=25, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=50, random_state=11, score=0.9845302280916689, total=   3.6s\n",
      "[CV] max_depth=25, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=50, random_state=11, score=0.9808882352399468, total=   3.9s\n",
      "[CV] max_depth=25, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=25, max_features=50, random_state=11, score=0.9814760194005298, total=   3.5s\n",
      "[CV] max_depth=25, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=25, max_features=50, random_state=11, score=0.9894810842392304, total=   3.5s\n",
      "[CV] max_depth=25, max_features=150, random_state=11 .................\n",
      "[CV] max_depth=25, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=25, max_features=150, random_state=11, score=0.9903275874874568, total=   5.2s\n",
      "[CV] max_depth=25, max_features=150, random_state=11 .................\n",
      "[CV] max_depth=50, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=150, random_state=11, score=0.9891113516125543, total=   5.9s\n",
      "[CV] max_depth=50, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=25, max_features=150, random_state=11, score=0.9869142977422204, total=   5.8s\n",
      "[CV]  max_depth=25, max_features=150, random_state=11, score=0.9921242659175464, total=   5.3s\n",
      "[CV] max_depth=50, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=10, random_state=11, score=0.988253236454538, total=   2.2s\n",
      "[CV]  max_depth=25, max_features=150, random_state=11, score=0.9928831999359852, total=   5.1s\n",
      "[CV] max_depth=50, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=10, random_state=11, score=0.9951492403608243, total=   2.5s\n",
      "[CV]  max_depth=50, max_features=10, random_state=11, score=0.996903013090955, total=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  43 out of  60 | elapsed:  1.3min remaining:   30.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=10, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=10, random_state=11, score=0.9917789125447565, total=   2.5s\n",
      "[CV] max_depth=50, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=10, random_state=11, score=0.9967137898086594, total=   2.5s\n",
      "[CV] max_depth=50, max_features=25, random_state=11 ..................\n",
      "[CV] max_depth=50, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=25, random_state=11, score=0.9971835615742568, total=   3.0s\n",
      "[CV]  max_depth=50, max_features=25, random_state=11, score=0.9971406816981984, total=   2.6s\n",
      "[CV] max_depth=50, max_features=25, random_state=11 ..................\n",
      "[CV] max_depth=50, max_features=25, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=25, random_state=11, score=0.996714668862188, total=   2.9s\n",
      "[CV] max_depth=50, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=25, random_state=11, score=0.9970456843350389, total=   2.9s\n",
      "[CV]  max_depth=50, max_features=25, random_state=11, score=0.9974005101335714, total=   2.9s\n",
      "[CV] max_depth=50, max_features=50, random_state=11 ..................\n",
      "[CV] max_depth=50, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=50, random_state=11, score=0.9966627601168492, total=   3.4s\n",
      "[CV] max_depth=50, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=50, random_state=11, score=0.9972288700680372, total=   3.3s\n",
      "[CV] max_depth=50, max_features=50, random_state=11 ..................\n",
      "[CV]  max_depth=50, max_features=50, random_state=11, score=0.9967364737418302, total=   3.4s\n",
      "[CV] max_depth=50, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=50, max_features=50, random_state=11, score=0.9971456052174542, total=   3.0s\n",
      "[CV] max_depth=50, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=50, max_features=50, random_state=11, score=0.9973222553444074, total=   3.8s\n",
      "[CV] max_depth=50, max_features=150, random_state=11 .................\n",
      "[CV] max_depth=50, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=50, max_features=150, random_state=11, score=0.9972427302145718, total=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 out of  60 | elapsed:  1.7min remaining:    7.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] max_depth=50, max_features=150, random_state=11 .................\n",
      "[CV]  max_depth=50, max_features=150, random_state=11, score=0.9968076709493288, total=   5.6s\n",
      "[CV]  max_depth=50, max_features=150, random_state=11, score=0.9967041939690265, total=   5.4s\n",
      "[CV]  max_depth=50, max_features=150, random_state=11, score=0.9967953445997629, total=   4.3s\n",
      "[CV]  max_depth=50, max_features=150, random_state=11, score=0.9970232470705802, total=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the most optimal parameters found within my grid search: \n",
      "\n",
      "{'max_depth': 50, 'max_features': 25, 'random_state': 11} \n",
      "\n",
      "This represents the model to use: \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
      "            max_features=25, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=11,\n",
      "            splitter='best') \n",
      "\n",
      "Train accuracy:  0.9986166795620267\n",
      "Validation accuracy:  0.9875095174214132 \n",
      "\n",
      "[[54425   412]\n",
      " [  277    48]] \n",
      "\n",
      "Accuracy: 0.99 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "mdl=DecisionTreeClassifier(criterion='gini', \n",
    "                       splitter='best', \n",
    "                       max_depth=10, \n",
    "                       min_samples_split=2, \n",
    "                       min_samples_leaf=1, \n",
    "                       min_weight_fraction_leaf=0.0, \n",
    "                       max_features=None, \n",
    "                       random_state=None, \n",
    "                       max_leaf_nodes=None, \n",
    "                       min_impurity_decrease=0.0, \n",
    "                       min_impurity_split=None, \n",
    "                       class_weight=None, \n",
    "                       presort=False)\n",
    "\n",
    "#create a dictionary of parameters for grid search \n",
    "param_grid = {'max_features':[10,25,50,150],\n",
    "'max_depth':[10,25,50],\n",
    "'random_state':[11]}\n",
    "\n",
    "#--------------------------------------\n",
    "mygrid = GridSearchCV(mdl, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)\n",
    "mygrid.fit(x_train, y_train)\n",
    "\n",
    "print(\"The following are the most optimal parameters found within my grid search:\",\"\\n\")\n",
    "print(mygrid.best_params_,\"\\n\" )\n",
    "print(\"This represents the model to use:\",\"\\n\")\n",
    "print(mygrid.best_estimator_,\"\\n\")\n",
    "\n",
    "#Fit to best parameters\n",
    "mytree=mygrid.best_estimator_\n",
    "mytree.fit(x_train, y_train)\n",
    "\n",
    "print(\"Train accuracy: \",mytree.score(x_train,y_train))\n",
    "print(\"Validation accuracy: \",mytree.score(x_val,y_val),\"\\n\")\n",
    "pred=mytree.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred),\"\\n\")\n",
    "\n",
    "\n",
    "# #CROSS VALIDATION\n",
    "scores = cross_val_score(mytree, x_train, y_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AssetLongitude</th>\n",
       "      <td>0.173099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Sqft</th>\n",
       "      <td>0.134903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.130379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AssetLatitude</th>\n",
       "      <td>0.104263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lat_city</th>\n",
       "      <td>0.095199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long_city</th>\n",
       "      <td>0.063136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_NY</th>\n",
       "      <td>0.016989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_West</th>\n",
       "      <td>0.015719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Healthcare</th>\n",
       "      <td>0.015432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_TX</th>\n",
       "      <td>0.015003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Industrial</th>\n",
       "      <td>0.012796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Retail</th>\n",
       "      <td>0.011474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Multi-Housing</th>\n",
       "      <td>0.010568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Office</th>\n",
       "      <td>0.010545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Charlotte-Gastonia-Rock Hill, NC-SC MSA</th>\n",
       "      <td>0.008036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0\n",
       "AssetLongitude                                      0.173099\n",
       "Size_Sqft                                           0.134903\n",
       "YearBuilt                                           0.130379\n",
       "AssetLatitude                                       0.104263\n",
       "Lat_city                                            0.095199\n",
       "Long_city                                           0.063136\n",
       "State_NY                                            0.016989\n",
       "Region_West                                         0.015719\n",
       "PropertyTypeGroup_Healthcare                        0.015432\n",
       "State_TX                                            0.015003\n",
       "PropertyType_Industrial                             0.012796\n",
       "PropertyType_Retail                                 0.011474\n",
       "PropertyTypeGroup_Multi-Housing                     0.010568\n",
       "PropertyType_Office                                 0.010545\n",
       "Market_name_Charlotte-Gastonia-Rock Hill, NC-SC...  0.008036"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature importances\n",
    "imps=pd.DataFrame(mytree.feature_importances_)\n",
    "imps.index=cols\n",
    "imps=imps.sort_values(by=0,axis=0,ascending=False)\n",
    "imps.iloc[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed: 41.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the most optimal parameters found within my grid search: \n",
      "\n",
      "{'max_depth': 50, 'max_features': 50, 'n_estimators': 25, 'random_state': 11} \n",
      "\n",
      "This represents the model to use: \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=50, max_features=50, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n",
      "            oob_score=False, random_state=11, verbose=0, warm_start=False) \n",
      "\n",
      "Train accuracy:  0.9999648308363227\n",
      "Validation accuracy:  0.9935825387041805 \n",
      "\n",
      "[[54764    73]\n",
      " [  281    44]] \n",
      "\n",
      "Accuracy: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "#Random forest + Grid search + Cross Validation\n",
    "\n",
    "#create base model \n",
    "mdl=RandomForestClassifier(n_estimators=2, \n",
    "                           criterion='gini', \n",
    "                           max_depth=None, \n",
    "                           min_samples_split=2, \n",
    "                           min_samples_leaf=1, \n",
    "                           min_weight_fraction_leaf=0.0, \n",
    "                           max_features='auto', \n",
    "                           max_leaf_nodes=None, \n",
    "                           min_impurity_decrease=0.0, \n",
    "                           min_impurity_split=None, \n",
    "                           bootstrap=True, \n",
    "                           oob_score=False, \n",
    "                           n_jobs=-1, \n",
    "                           random_state=None, \n",
    "                           verbose=0, \n",
    "                           warm_start=False, \n",
    "                           class_weight=None)\n",
    "\n",
    "#create a dictionary of parameters for grid search \n",
    "param_grid = {'n_estimators':[5, 10, 25],\n",
    "'max_features':[25,50,200],\n",
    "'max_depth':[25,50,75],\n",
    "'random_state':[11]}\n",
    "\n",
    "#--------------------------------------\n",
    "mygrid = GridSearchCV(mdl, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)\n",
    "mygrid.fit(x_train, y_train)\n",
    "\n",
    "print(\"The following are the most optimal parameters found within my grid search:\",\"\\n\")\n",
    "print(mygrid.best_params_,\"\\n\" )\n",
    "print(\"This represents the model to use:\",\"\\n\")\n",
    "print(mygrid.best_estimator_,\"\\n\")\n",
    "\n",
    "#Fit to best parameters\n",
    "randforest=mygrid.best_estimator_\n",
    "randforest.fit(x_train, y_train)\n",
    "\n",
    "print(\"Train accuracy: \",randforest.score(x_train,y_train))\n",
    "print(\"Validation accuracy: \",randforest.score(x_val,y_val),\"\\n\")\n",
    "pred=randforest.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred),\"\\n\")\n",
    "\n",
    "\n",
    "# #CROSS VALIDATION\n",
    "scores = cross_val_score(randforest, x_train, y_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  20 | elapsed:  2.6min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:  6.2min remaining:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  8.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the most optimal parameters found within my grid search: \n",
      "\n",
      "{'max_iter': 100, 'random_state': 11, 'tol': 0.001} \n",
      "\n",
      "This represents the model to use: \n",
      "\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=100,\n",
      "     multi_class='ovr', penalty='l2', random_state=11, tol=0.001,\n",
      "     verbose=0) \n",
      "\n",
      "Train accuracy:  0.7039655185888568\n",
      "Validation accuracy:  0.6614154671694282 \n",
      "\n",
      "[[36256 18581]\n",
      " [   96   229]] \n",
      "\n",
      "Accuracy: 0.70 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "mdl=LinearSVC(penalty='l2', \n",
    "              loss='squared_hinge', \n",
    "              dual=True, \n",
    "              tol=0.0001, \n",
    "              C=1.0, \n",
    "              multi_class='ovr', \n",
    "              fit_intercept=True, \n",
    "              intercept_scaling=1, \n",
    "              class_weight=None, \n",
    "              verbose=0, \n",
    "              random_state=None, \n",
    "              max_iter=1000)\n",
    "       \n",
    "    \n",
    "#create a dictionary of parameters for grid search \n",
    "param_grid = {'tol':[0.001, 0.0001],\n",
    "'max_iter':[100,250],\n",
    "'random_state':[11]}\n",
    "\n",
    "#--------------------------------------\n",
    "mygrid = GridSearchCV(mdl, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)\n",
    "mygrid.fit(x_train, y_train)\n",
    "\n",
    "print(\"The following are the most optimal parameters found within my grid search:\",\"\\n\")\n",
    "print(mygrid.best_params_,\"\\n\" )\n",
    "print(\"This represents the model to use:\",\"\\n\")\n",
    "print(mygrid.best_estimator_,\"\\n\")\n",
    "\n",
    "#Fit to best parameters\n",
    "SVC=mygrid.best_estimator_\n",
    "SVC.fit(x_train, y_train)\n",
    "\n",
    "print(\"Train accuracy: \",SVC.score(x_train,y_train))\n",
    "print(\"Validation accuracy: \",SVC.score(x_val,y_val),\"\\n\")\n",
    "pred=SVC.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred),\"\\n\")\n",
    "\n",
    "\n",
    "# probs=SVC.predict_proba(x_val) #SCREEN FOR PREDICTION OF y=1 PROBS\n",
    "# print(\"ROC AUC score\")\n",
    "# print(roc_auc_score(y_val, probs),\"\\n\")\n",
    "\n",
    "\n",
    "# #CROSS VALIDATION\n",
    "scores = cross_val_score(SVC, x_train, y_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  30 | elapsed: 15.9min remaining:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 17.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the most optimal parameters found within my grid search: \n",
      "\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'n_estimators': 10, 'random_state': 11} \n",
      "\n",
      "This represents the model to use: \n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=10, random_state=11) \n",
      "\n",
      "Train accuracy:  0.7586613834767454\n",
      "Validation accuracy:  0.7511511547804648 \n",
      "\n",
      "[[41238 13599]\n",
      " [  128   197]] \n",
      "\n",
      "Accuracy: 0.76 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "mdl=AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), \n",
    "                         n_estimators=1, \n",
    "                         learning_rate=1.0, \n",
    "                         algorithm='SAMME.R', \n",
    "                         random_state=None)\n",
    "\n",
    "\n",
    "#create a dictionary of parameters for grid search \n",
    "param_grid = {'base_estimator':[logit,DecisionTreeClassifier(max_depth=5)],\n",
    "'n_estimators':[2,5,10],\n",
    "'random_state':[11]}\n",
    "\n",
    "#--------------------------------------\n",
    "mygrid = GridSearchCV(mdl, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)\n",
    "mygrid.fit(x_train, y_train)\n",
    "\n",
    "print(\"The following are the most optimal parameters found within my grid search:\",\"\\n\")\n",
    "print(mygrid.best_params_,\"\\n\" )\n",
    "print(\"This represents the model to use:\",\"\\n\")\n",
    "print(mygrid.best_estimator_,\"\\n\")\n",
    "\n",
    "#Fit to best parameters\n",
    "boost=mygrid.best_estimator_\n",
    "boost.fit(x_train, y_train)\n",
    "\n",
    "print(\"Train accuracy: \",boost.score(x_train,y_train))\n",
    "print(\"Validation accuracy: \",boost.score(x_val,y_val),\"\\n\")\n",
    "pred=boost.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred),\"\\n\")\n",
    "\n",
    "\n",
    "# probs=SVC.predict_proba(x_val) #SCREEN FOR PREDICTION OF y=1 PROBS\n",
    "# print(\"ROC AUC score\")\n",
    "# print(roc_auc_score(y_val, probs),\"\\n\")\n",
    "\n",
    "\n",
    "# #CROSS VALIDATION\n",
    "scores = cross_val_score(boost, x_train, y_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  7.2min remaining: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  7.6min remaining:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed: 11.5min remaining:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the most optimal parameters found within my grid search: \n",
      "\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'n_estimators': 10, 'random_state': 11} \n",
      "\n",
      "This represents the model to use: \n",
      "\n",
      "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=False,\n",
      "         random_state=11, verbose=0, warm_start=False) \n",
      "\n",
      "Train accuracy:  0.6470891655529765\n",
      "Validation accuracy:  0.833961785286973 \n",
      "\n",
      "[[45845  8992]\n",
      " [  167   158]] \n",
      "\n",
      "Accuracy: 0.65 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "mdl=BaggingClassifier(base_estimator=mytree,  \n",
    "                  n_estimators=2, #How many to ensemble?\n",
    "                  max_samples=1.0, \n",
    "                  max_features=1.0, \n",
    "                  bootstrap=True, \n",
    "                  bootstrap_features=False, \n",
    "                  oob_score=False, \n",
    "                  warm_start=False, \n",
    "                  n_jobs=-1, \n",
    "                  random_state=1, \n",
    "                  verbose=0)\n",
    "\n",
    "#create a dictionary of parameters for grid search \n",
    "param_grid = {'base_estimator':[DecisionTreeClassifier(max_depth=5)],\n",
    "'n_estimators':[2,5,10],\n",
    "'random_state':[11]}\n",
    "\n",
    "#--------------------------------------\n",
    "mygrid = GridSearchCV(mdl, param_grid, cv = 5, scoring = 'roc_auc',refit = True, n_jobs=-1, verbose = 5)\n",
    "mygrid.fit(x_train, y_train)\n",
    "\n",
    "print(\"The following are the most optimal parameters found within my grid search:\",\"\\n\")\n",
    "print(mygrid.best_params_,\"\\n\" )\n",
    "print(\"This represents the model to use:\",\"\\n\")\n",
    "print(mygrid.best_estimator_,\"\\n\")\n",
    "\n",
    "#Fit to best parameters\n",
    "Bags=mygrid.best_estimator_\n",
    "Bags.fit(x_train, y_train)\n",
    "\n",
    "print(\"Train accuracy: \",Bags.score(x_train,y_train))\n",
    "print(\"Validation accuracy: \",Bags.score(x_val,y_val),\"\\n\")\n",
    "pred=Bags.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred),\"\\n\")\n",
    "\n",
    "\n",
    "# probs=SVC.predict_proba(x_val) #SCREEN FOR PREDICTION OF y=1 PROBS\n",
    "# print(\"ROC AUC score\")\n",
    "# print(roc_auc_score(y_val, probs),\"\\n\")\n",
    "\n",
    "\n",
    "# #CROSS VALIDATION\n",
    "scores = cross_val_score(Bags, x_train, y_train, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Validation accuracy:  0.6627025851129401 \n",
      "\n",
      "[[36333 18504]\n",
      " [  102   223]]\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Validation accuracy:  0.9865124542257351 \n",
      "\n",
      "[[54374   463]\n",
      " [  281    44]]\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Validation accuracy:  0.9935825387041805 \n",
      "\n",
      "[[54764    73]\n",
      " [  281    44]]\n",
      "\n",
      "\n",
      "SVM\n",
      "Validation accuracy:  0.6614154671694282 \n",
      "\n",
      "[[36256 18581]\n",
      " [   96   229]]\n",
      "\n",
      "\n",
      "Boosting\n",
      "Validation accuracy:  0.7511511547804648 \n",
      "\n",
      "[[41238 13599]\n",
      " [  128   197]]\n",
      "\n",
      "\n",
      "Bagging\n",
      "Validation accuracy:  0.833961785286973 \n",
      "\n",
      "[[45845  8992]\n",
      " [  167   158]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAINING RESULTS\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Validation accuracy: \",logit.score(x_val,y_val) ,\"\\n\")\n",
    "pred=logit.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred, labels=None, sample_weight=None))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(\"Validation accuracy: \",mytree.score(x_val,y_val) ,\"\\n\")\n",
    "pred=mytree.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred, labels=None, sample_weight=None))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"Validation accuracy: \",randforest.score(x_val,y_val) ,\"\\n\")\n",
    "pred=randforest.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred, labels=None, sample_weight=None))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"Validation accuracy: \",SVC.score(x_val,y_val) ,\"\\n\")\n",
    "pred=SVC.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred, labels=None, sample_weight=None))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Boosting\")\n",
    "print(\"Validation accuracy: \",boost.score(x_val,y_val) ,\"\\n\")\n",
    "pred=boost.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred, labels=None, sample_weight=None))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Bagging\")\n",
    "print(\"Validation accuracy: \",Bags.score(x_val,y_val) ,\"\\n\")\n",
    "pred=Bags.predict(x_val)\n",
    "print(confusion_matrix(y_val, pred, labels=None, sample_weight=None))\n",
    "print(\"\\n\")\n",
    "\n",
    "# print(\"Ensemble\")\n",
    "# print(\"test accuracy: \",ensemble.score(x_test,y_test) ,\"\\n\")\n",
    "# pred=ensemble.predict(x_test)\n",
    "# print(confusion_matrix(y_test, pred, labels=None, sample_weight=None))\n",
    "# print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare process for TEST results\n",
    "\n",
    "def test_run(mdl,test_threshold=np.datetime64('2017-01-01')):\n",
    "    #Prepare process for TEST results\n",
    "    dates.append(test_threshold)\n",
    "    print(\"Testing LTM of date:\",test_threshold)\n",
    "    #Drop non-predictor columns\n",
    "    assets_train=assets.copy()\n",
    "    asides=['City','CountryID']\n",
    "    assets_train=assets_train.drop(asides,axis=1)\n",
    "    assets_train=pd.get_dummies(assets_train)\n",
    "\n",
    "    #---y values based on date range---\n",
    "    #for testing\n",
    "    zero_test=test_threshold-365\n",
    "    tx_test=tx.copy()\n",
    "    tx_test.loc[:,'y']=0\n",
    "    tx_test.loc[tx.AccountingDate<=test_threshold,'y']=1\n",
    "    tx_test.loc[tx.AccountingDate<=zero_test,'y']=0\n",
    "\n",
    "    #for fitting\n",
    "    train_threshold=zero_test #test_threshold \n",
    "    zero_train=train_threshold-365\n",
    "    tx_train=tx.copy()\n",
    "    tx_train.loc[:,'y']=0\n",
    "    tx_train.loc[tx.AccountingDate<=train_threshold,'y']=1\n",
    "    tx_train.loc[tx.AccountingDate<=zero_train,'y']=0\n",
    "    #--------------------------------\n",
    "    assets_train.loc[:,\"y\"] = 0\n",
    "    Sold_IDs=list(tx_train.loc[tx_train.y==1,'AssetID']) #Asset IDs of y=1 properties\n",
    "    for i in Sold_IDs:\n",
    "        assets_train.loc[assets_train.AssetID ==i,\"y\"] =1\n",
    "\n",
    "\n",
    "    #Split train into y=1 and y=0 for upsampling to fit\n",
    "    filter_train=(tx.AccountingDate>zero_train) & (tx.AccountingDate<=train_threshold)\n",
    "    IDs=tx.loc[filter_train,\"AssetID\"]\n",
    "    train_1=assets_train.loc[assets_train.AssetID.isin(IDs),:] \n",
    "    train_0=assets_train.loc[~assets_train.AssetID.isin(IDs),:] \n",
    "\n",
    "    #----------------                \n",
    "    #Due to imbalanced dataset, we split y=1 and y=0 BEFORE upsampling\n",
    "    train_1, test_1 = train_test_split(train_1, test_size = 0.3, random_state = 43)\n",
    "    train_0, test_0 = train_test_split(train_0, test_size = 0.3, random_state = 43)\n",
    "    #----------------\n",
    "\n",
    "    #Upsample y=1 to match count of y=0 using random selection\n",
    "    train_1_indexes = np.random.choice(train_1.index, size=len(train_0)-len(train_1), replace=True)\n",
    "    train_1_up=train_1.loc[train_1_indexes,:]\n",
    "    train_1=pd.concat((train_1,train_1_up))\n",
    "\n",
    "    test=pd.concat((test_1,test_0))\n",
    "    train=pd.concat((train_1,train_0))\n",
    "    #----------------\n",
    "    #Updating y values for test\n",
    "    test.loc[:,\"y\"]=0\n",
    "    Sold_IDs=list(tx_train.loc[tx_train.y>0,'AssetID']) #Asset IDs of y=1 properties\n",
    "    for i in Sold_IDs:\n",
    "        test.loc[test.AssetID ==i,\"y\"] =1\n",
    "\n",
    "    train=train.drop(['AssetID'],axis=1)\n",
    "    test=test.drop(['AssetID'],axis=1)\n",
    "    #----------------\n",
    "    #Predictors\n",
    "    x_train=train.drop(columns='y')\n",
    "    x_test=test.drop(columns='y')\n",
    "\n",
    "    #Target\n",
    "    y_train = train.loc[:,\"y\"]\n",
    "    y_test= test.loc[:,\"y\"]\n",
    "    #----------------\n",
    "    #Normalize data 0-1\n",
    "    #Save column names\n",
    "    cols=list(x_train)\n",
    "\n",
    "    # #Scale the data\n",
    "    std_scale = MinMaxScaler().fit(x_train)\n",
    "    x_train = std_scale.transform(x_train) \n",
    "    x_test = std_scale.transform(x_test) \n",
    "\n",
    "    #Return to pandas dataframe from numpy array\n",
    "    x_train=pd.DataFrame(x_train)\n",
    "    x_train.columns=cols\n",
    "    x_test=pd.DataFrame(x_test)\n",
    "    x_test.columns=cols\n",
    "    #----------------\n",
    "    mdl.fit(x_train, y_train)\n",
    "    train_scores.append(mdl.score(x_train,y_train))\n",
    "    test_scores.append(mdl.score(x_test,y_test))\n",
    "    print(\"Train accuracy: \",mdl.score(x_train,y_train))\n",
    "    print(\"Test accuracy: \",mdl.score(x_test,y_test),\"\\n\")\n",
    "    pred=mdl.predict(x_test)\n",
    "    print(np.round(confusion_matrix(y_test, pred)/np.sum(confusion_matrix(y_test, pred)),3),\"\\n\")\n",
    "    pn=confusion_matrix(y_test, pred)[0][0]/(confusion_matrix(y_test, pred)[0][0]+confusion_matrix(y_test, pred)[1][0])\n",
    "    pp=confusion_matrix(y_test, pred)[1][1]/(confusion_matrix(y_test, pred)[0][1]+confusion_matrix(y_test, pred)[1][1])\n",
    "    print(\"Predicted Neg. rate:\",pn ,\"Predicted Pos. rate:\",pp,\"\\n\")\n",
    "    PN.append(pn)\n",
    "    PP.append(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LTM of date: 2015-01-01\n",
      "Train accuracy:  0.7224670634394428\n",
      "Test accuracy:  0.6901819367932734 \n",
      "\n",
      "[[0.687 0.308]\n",
      " [0.001 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.9978689257807362 Predicted Pos. rate: 0.00925764192139738 \n",
      "\n",
      "Testing LTM of date: 2016-01-01\n",
      "Train accuracy:  0.7157800685139954\n",
      "Test accuracy:  0.6416055087433179 \n",
      "\n",
      "[[0.638 0.357]\n",
      " [0.002 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.9976493911073351 Predicted Pos. rate: 0.009056603773584906 \n",
      "\n",
      "Testing LTM of date: 2016-12-31\n",
      "Train accuracy:  0.719139996563735\n",
      "Test accuracy:  0.6878986662800812 \n",
      "\n",
      "[[0.684 0.31 ]\n",
      " [0.002 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9970168954593454 Predicted Pos. rate: 0.011211280628756357 \n",
      "\n",
      "Testing LTM of date: 2017-12-31\n",
      "Train accuracy:  0.6730835352035633\n",
      "Test accuracy:  0.6068063206726587 \n",
      "\n",
      "[[0.603 0.391]\n",
      " [0.002 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9963463208649037 Predicted Pos. rate: 0.00995732574679943 \n",
      "\n",
      "Testing LTM of date: 2018-12-31\n",
      "Train accuracy:  0.7212881541407746\n",
      "Test accuracy:  0.6672405044940563 \n",
      "\n",
      "[[0.663 0.33 ]\n",
      " [0.002 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9965144459875283 Predicted Pos. rate: 0.012242023725691999 \n",
      "\n",
      "Testing LTM of date: 2015-01-01\n",
      "Train accuracy:  0.9997932933440457\n",
      "Test accuracy:  0.99237097709481 \n",
      "\n",
      "[[0.992 0.004]\n",
      " [0.004 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9962139827809025 Predicted Pos. rate: 0.1306122448979592 \n",
      "\n",
      "Testing LTM of date: 2016-01-01\n",
      "Train accuracy:  0.9995825172260415\n",
      "Test accuracy:  0.9907764791157018 \n",
      "\n",
      "[[0.99  0.005]\n",
      " [0.004 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9957723636496164 Predicted Pos. rate: 0.10064935064935066 \n",
      "\n",
      "Testing LTM of date: 2016-12-31\n",
      "Train accuracy:  0.9999297127594771\n",
      "Test accuracy:  0.9907400695853871 \n",
      "\n",
      "[[0.99  0.004]\n",
      " [0.005 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9950644714795658 Predicted Pos. rate: 0.13043478260869565 \n",
      "\n",
      "Testing LTM of date: 2017-12-31\n",
      "Train accuracy:  0.9902242713135891\n",
      "Test accuracy:  0.9697376051029284 \n",
      "\n",
      "[[0.969 0.025]\n",
      " [0.005 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9948444973850249 Predicted Pos. rate: 0.04261168384879725 \n",
      "\n",
      "Testing LTM of date: 2018-12-31\n",
      "Train accuracy:  0.9968343299331692\n",
      "Test accuracy:  0.9840352276022035 \n",
      "\n",
      "[[0.983 0.011]\n",
      " [0.005 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.994627303566517 Predicted Pos. rate: 0.09399075500770417 \n",
      "\n",
      "Testing LTM of date: 2015-01-01\n",
      "Train accuracy:  0.9998946966092308\n",
      "Test accuracy:  0.9949623079153378 \n",
      "\n",
      "[[0.994 0.001]\n",
      " [0.004 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9962418300653595 Predicted Pos. rate: 0.3173076923076923 \n",
      "\n",
      "Testing LTM of date: 2016-01-01\n",
      "Train accuracy:  0.9999102607121397\n",
      "Test accuracy:  0.9945637401467791 \n",
      "\n",
      "[[0.994 0.001]\n",
      " [0.004 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9958784225433945 Predicted Pos. rate: 0.3302752293577982 \n",
      "\n",
      "Testing LTM of date: 2016-12-31\n",
      "Train accuracy:  0.9999179982193899\n",
      "Test accuracy:  0.9940018846042331 \n",
      "\n",
      "[[0.993 0.001]\n",
      " [0.005 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9952244334689134 Predicted Pos. rate: 0.39285714285714285 \n",
      "\n",
      "Testing LTM of date: 2017-12-31\n",
      "Train accuracy:  0.9999413925138705\n",
      "Test accuracy:  0.9934582487677588 \n",
      "\n",
      "[[0.993 0.001]\n",
      " [0.005 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9947873151948854 Predicted Pos. rate: 0.4126984126984127 \n",
      "\n",
      "Testing LTM of date: 2018-12-31\n",
      "Train accuracy:  0.999933560010943\n",
      "Test accuracy:  0.9931683096549725 \n",
      "\n",
      "[[0.992 0.001]\n",
      " [0.005 0.001]] \n",
      "\n",
      "Predicted Neg. rate: 0.9944968125102163 Predicted Pos. rate: 0.408 \n",
      "\n",
      "Testing LTM of date: 2015-01-01\n",
      "Train accuracy:  0.8231605057682857\n",
      "Test accuracy:  0.7804436068425631 \n",
      "\n",
      "[[0.778 0.218]\n",
      " [0.002 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.9976528003718336 Predicted Pos. rate: 0.011436564094125391 \n",
      "\n",
      "Testing LTM of date: 2016-01-01\n",
      "Train accuracy:  0.8013328235101327\n",
      "Test accuracy:  0.7075835824952432 \n",
      "\n",
      "[[0.705 0.291]\n",
      " [0.002 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.9975114805408041 Predicted Pos. rate: 0.010243119832160929 \n",
      "\n",
      "Testing LTM of date: 2016-12-31\n",
      "Train accuracy:  0.7755337925433048\n",
      "Test accuracy:  0.7295411713540156 \n",
      "\n",
      "[[0.726 0.268]\n",
      " [0.002 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.9968659834842304 Predicted Pos. rate: 0.012082777036048063 \n",
      "\n",
      "Testing LTM of date: 2017-12-31\n",
      "Train accuracy:  0.764562006720325\n",
      "Test accuracy:  0.6991881704841983 \n",
      "\n",
      "[[0.695 0.298]\n",
      " [0.002 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9965980211390136 Predicted Pos. rate: 0.01247226719433951 \n",
      "\n",
      "Testing LTM of date: 2018-12-31\n",
      "Train accuracy:  0.7803572126470474\n",
      "Test accuracy:  0.7535155117425341 \n",
      "\n",
      "[[0.75  0.244]\n",
      " [0.003 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9961490324444017 Predicted Pos. rate: 0.014227046054561454 \n",
      "\n",
      "Testing LTM of date: 2015-01-01\n",
      "Train accuracy:  0.7228882770025195\n",
      "Test accuracy:  0.6863764859379531 \n",
      "\n",
      "[[0.684 0.312]\n",
      " [0.001 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.9978307452183804 Predicted Pos. rate: 0.009089340159926365 \n",
      "\n",
      "Testing LTM of date: 2016-01-01\n",
      "Train accuracy:  0.7119017705951666\n",
      "Test accuracy:  0.6336685693576153 \n",
      "\n",
      "[[0.63  0.365]\n",
      " [0.001 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.9977055010612058 Predicted Pos. rate: 0.009006348737634727 \n",
      "\n",
      "Testing LTM of date: 2016-12-31\n",
      "Train accuracy:  0.7136302578760758\n",
      "Test accuracy:  0.6840207306465642 \n",
      "\n",
      "[[0.68  0.314]\n",
      " [0.002 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9970527321969094 Predicted Pos. rate: 0.01118593767834722 \n",
      "\n",
      "Testing LTM of date: 2017-12-31\n",
      "Train accuracy:  0.6740095334844104\n",
      "Test accuracy:  0.6059365033342998 \n",
      "\n",
      "[[0.602 0.392]\n",
      " [0.002 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9962815245749242 Predicted Pos. rate: 0.009845674772175666 \n",
      "\n",
      "Testing LTM of date: 2018-12-31\n",
      "Train accuracy:  0.7187438933833588\n",
      "Test accuracy:  0.6641417802261526 \n",
      "\n",
      "[[0.66  0.334]\n",
      " [0.002 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9965796530400044 Predicted Pos. rate: 0.012286726043566907 \n",
      "\n",
      "Testing LTM of date: 2015-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:605: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/usr/local/Anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:610: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions.sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6823932730633926\n",
      "Test accuracy:  0.6361264134531749 \n",
      "\n",
      "[[0.633 0.363]\n",
      " [0.001 0.003]] \n",
      "\n",
      "Predicted Neg. rate: 0.99785799965728 Predicted Pos. rate: 0.008180466038671294 \n",
      "\n",
      "Testing LTM of date: 2016-01-01\n",
      "Train accuracy:  0.6703758905648893\n",
      "Test accuracy:  0.5008426202772492 \n",
      "\n",
      "[[0.497 0.498]\n",
      " [0.001 0.004]] \n",
      "\n",
      "Predicted Neg. rate: 0.9979265187340851 Predicted Pos. rate: 0.007438165733886983 \n",
      "\n",
      "Testing LTM of date: 2016-12-31\n",
      "Train accuracy:  0.6621253299595458\n",
      "Test accuracy:  0.8587271672948681 \n",
      "\n",
      "[[0.857 0.138]\n",
      " [0.003 0.002]] \n",
      "\n",
      "Predicted Neg. rate: 0.996017615204703 Predicted Pos. rate: 0.015275080906148868 \n",
      "\n",
      "Testing LTM of date: 2017-12-31\n",
      "Train accuracy:  0.6291122919434242\n",
      "Test accuracy:  0.39928240069585386 \n",
      "\n",
      "[[0.394 0.6  ]\n",
      " [0.001 0.005]] \n",
      "\n",
      "Predicted Neg. rate: 0.997112872920581 Predicted Pos. rate: 0.008272637352756048 \n",
      "\n",
      "Testing LTM of date: 2018-12-31\n",
      "Train accuracy:  0.6438699339508344\n",
      "Test accuracy:  0.813877210785735 \n",
      "\n",
      "[[0.812 0.182]\n",
      " [0.004 0.002]] \n",
      "\n",
      "Predicted Neg. rate: 0.9950449950005555 Predicted Pos. rate: 0.012869633559288732 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "\n",
    "\n",
    "logit=LogisticRegression(penalty='l2',dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, \n",
    "                         solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "tree=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
    "            max_features=50, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=11,\n",
    "            splitter='best')\n",
    "\n",
    "randforest=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=75, max_features=25, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n",
    "            oob_score=False, random_state=11, verbose=0, warm_start=False) \n",
    "\n",
    "boost=AdaBoostClassifier(algorithm='SAMME.R',\n",
    "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'),\n",
    "          learning_rate=1.0, n_estimators=10, random_state=11) \n",
    "\n",
    "svm=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
    "     intercept_scaling=1, loss='squared_hinge', max_iter=500,\n",
    "     multi_class='ovr', penalty='l2', random_state=11, tol=0.001,\n",
    "     verbose=0)\n",
    "\n",
    "\n",
    "bags=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best'),\n",
    "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
    "         max_samples=1.0, n_estimators=10, n_jobs=-1, oob_score=True,\n",
    "         random_state=11, verbose=0, warm_start=False) \n",
    "\n",
    "models=[logit,tree,randforest,boost,svm,bags]\n",
    "\n",
    "all_scores=[]\n",
    "PPs=[]\n",
    "PNs=[]\n",
    "for i in models:\n",
    "    test_threshold=np.datetime64('2015-01-01')\n",
    "    dates=[]\n",
    "    train_scores=[]\n",
    "    test_scores=[]\n",
    "    PP=[]\n",
    "    PN=[]\n",
    "    for j in range(5):\n",
    "        test_run(mdl=i,test_threshold=test_threshold)\n",
    "        test_threshold+=365\n",
    "    all_scores.append(test_scores)\n",
    "    PPs.append(PP)\n",
    "    PNs.append(PN)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logit</th>\n",
       "      <th>tree</th>\n",
       "      <th>randforest</th>\n",
       "      <th>boost</th>\n",
       "      <th>svm</th>\n",
       "      <th>bags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.130612</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.008180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.100649</td>\n",
       "      <td>0.330275</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.007438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011211</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.015275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.042612</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.012472</td>\n",
       "      <td>0.009846</td>\n",
       "      <td>0.008273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012242</td>\n",
       "      <td>0.093991</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.012287</td>\n",
       "      <td>0.012870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      logit      tree  randforest     boost       svm      bags\n",
       "0  0.009258  0.130612    0.317308  0.011437  0.009089  0.008180\n",
       "1  0.009057  0.100649    0.330275  0.010243  0.009006  0.007438\n",
       "2  0.011211  0.130435    0.392857  0.012083  0.011186  0.015275\n",
       "3  0.009957  0.042612    0.412698  0.012472  0.009846  0.008273\n",
       "4  0.012242  0.093991    0.408000  0.014227  0.012287  0.012870"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names=['logit','tree','randforest','boost','svm','bags']\n",
    "# results=pd.DataFrame(index=model_names)\n",
    "# results\n",
    "\n",
    "df = pd.DataFrame(PPs)\n",
    "df = df.transpose()\n",
    "df.columns = model_names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9c4e79b278>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data\n",
    "x = (range(2015,2020))\n",
    "logistic= df.iloc[:,0]\n",
    "trees= df.iloc[:,1]\n",
    "randforests= df.iloc[:,2]\n",
    "boosting= df.iloc[:,3]\n",
    "SVM= df.iloc[:,4]\n",
    "bagging= df.iloc[:,5]\n",
    "            \n",
    " \n",
    "# multiple line plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Precision Rate\",fontsize=20)\n",
    "plt.plot( x, randforests, marker='X', markerfacecolor='red', markersize=12,color='salmon', linewidth=2)\n",
    "plt.plot( x, trees, marker='.',markerfacecolor='violet', markersize=25, color='purple', linewidth=2, linestyle='dashed')\n",
    "plt.plot( x, boosting, marker='>',markerfacecolor='green', markersize=12, color='springgreen', linewidth=2)\n",
    "plt.plot( x, SVM, marker='p', markerfacecolor='moccasin', markersize=12,color='tan', linewidth=2)\n",
    "plt.plot( x, logistic, marker='o', markerfacecolor='blue', markersize=12, color='skyblue', linewidth=2)\n",
    "plt.plot( x, bagging, marker='d', markerfacecolor='black', markersize=12,color='lightgrey', linewidth=2)\n",
    "plt.legend(fontsize=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rerun random forest, collect each year's results, analyze each random forest's 25 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AssetLongitude</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AssetLatitude</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Sqft</th>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long_city</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lat_city</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Healthcare</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Self Storage</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region_Southwest</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Industrial</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_NJ</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Multi-Housing</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Office</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Retail</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Retail</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Office</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyTypeGroup_Hotel-Lodging</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Seniors Housing</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Hotel/Lodging</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsGateway</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Apartments</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Land</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PropertyType_Industrial</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Mansfield, OH MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Lynchburg, VA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Macon, GA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Madison, WI MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Milwaukee-Racine, WI CMSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Minneapolis-St. Paul, MN-WI MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_McAllen-Edinburg-Mission, TX MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Baton Rouge, LA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Barnstable-Yarmouth, MA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Bangor, ME MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Bakersfield, CA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Austin-San Marcos, TX MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Augusta-Aiken, GA-SC MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Auburn-Opelika, AL MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Boston-Worcester-Lawrence, MA-NH-ME-CT CMSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Bryan-College Station, TX MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Columbia, SC MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Chattanooga, TN-GA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Columbia, MO MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Colorado Springs, CO MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Cleveland-Akron, OH CMSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Clarksville-Hopkinsville, TN-KY MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Cincinnati-Hamilton, OH-KY-IN CMSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Chico-Paradise, CA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Chicago-Gary-Kenosha, IL-IN-WI CMSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Cheyenne, WY MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Charlottesville, VA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Buffalo-Niagara Falls, NY MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Charlotte-Gastonia-Rock Hill, NC-SC MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Charleston-North Charleston, SC MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Charleston, WV MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Champaign-Urbana, IL MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Cedar Rapids, IA MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Casper, WY MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Canton-Massillon, OH MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Burlington, VT MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Market_name_Yuma, AZ MSA</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Importance\n",
       "AssetLongitude                                            0.14\n",
       "AssetLatitude                                             0.13\n",
       "Size_Sqft                                                 0.13\n",
       "YearBuilt                                                 0.12\n",
       "Long_city                                                 0.08\n",
       "Lat_city                                                  0.08\n",
       "PropertyTypeGroup_Healthcare                              0.02\n",
       "PropertyType_Self Storage                                 0.01\n",
       "Region_Southwest                                          0.01\n",
       "PropertyTypeGroup_Industrial                              0.01\n",
       "State_NJ                                                  0.01\n",
       "PropertyTypeGroup_Multi-Housing                           0.01\n",
       "PropertyTypeGroup_Office                                  0.01\n",
       "PropertyTypeGroup_Retail                                  0.01\n",
       "PropertyType_Retail                                       0.01\n",
       "PropertyType_Office                                       0.01\n",
       "PropertyTypeGroup_Hotel-Lodging                           0.01\n",
       "PropertyType_Seniors Housing                              0.01\n",
       "PropertyType_Hotel/Lodging                                0.01\n",
       "IsGateway                                                 0.01\n",
       "PropertyType_Apartments                                   0.01\n",
       "PropertyType_Land                                         0.01\n",
       "PropertyType_Industrial                                   0.01\n",
       "Market_name_Mansfield, OH MSA                             0.00\n",
       "Market_name_Lynchburg, VA MSA                             0.00\n",
       "Market_name_Macon, GA MSA                                 0.00\n",
       "Market_name_Madison, WI MSA                               0.00\n",
       "Market_name_Milwaukee-Racine, WI CMSA                     0.00\n",
       "Market_name_Minneapolis-St. Paul, MN-WI MSA               0.00\n",
       "Market_name_McAllen-Edinburg-Mission, TX MSA              0.00\n",
       "...                                                        ...\n",
       "Market_name_Baton Rouge, LA MSA                           0.00\n",
       "Market_name_Barnstable-Yarmouth, MA MSA                   0.00\n",
       "Market_name_Bangor, ME MSA                                0.00\n",
       "Market_name_Bakersfield, CA MSA                           0.00\n",
       "Market_name_Austin-San Marcos, TX MSA                     0.00\n",
       "Market_name_Augusta-Aiken, GA-SC MSA                      0.00\n",
       "Market_name_Auburn-Opelika, AL MSA                        0.00\n",
       "Market_name_Boston-Worcester-Lawrence, MA-NH-ME...        0.00\n",
       "Market_name_Bryan-College Station, TX MSA                 0.00\n",
       "Market_name_Columbia, SC MSA                              0.00\n",
       "Market_name_Chattanooga, TN-GA MSA                        0.00\n",
       "Market_name_Columbia, MO MSA                              0.00\n",
       "Market_name_Colorado Springs, CO MSA                      0.00\n",
       "Market_name_Cleveland-Akron, OH CMSA                      0.00\n",
       "Market_name_Clarksville-Hopkinsville, TN-KY MSA           0.00\n",
       "Market_name_Cincinnati-Hamilton, OH-KY-IN CMSA            0.00\n",
       "Market_name_Chico-Paradise, CA MSA                        0.00\n",
       "Market_name_Chicago-Gary-Kenosha, IL-IN-WI CMSA           0.00\n",
       "Market_name_Cheyenne, WY MSA                              0.00\n",
       "Market_name_Charlottesville, VA MSA                       0.00\n",
       "Market_name_Buffalo-Niagara Falls, NY MSA                 0.00\n",
       "Market_name_Charlotte-Gastonia-Rock Hill, NC-SC...        0.00\n",
       "Market_name_Charleston-North Charleston, SC MSA           0.00\n",
       "Market_name_Charleston, WV MSA                            0.00\n",
       "Market_name_Champaign-Urbana, IL MSA                      0.00\n",
       "Market_name_Cedar Rapids, IA MSA                          0.00\n",
       "Market_name_Casper, WY MSA                                0.00\n",
       "Market_name_Canton-Massillon, OH MSA                      0.00\n",
       "Market_name_Burlington, VT MSA                            0.00\n",
       "Market_name_Yuma, AZ MSA                                  0.00\n",
       "\n",
       "[375 rows x 1 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(np.round(randforest.feature_importances_,2),\n",
    "                                   index = x_train.columns,\n",
    "                                    columns=['Importance']).sort_values('Importance',\n",
    "                                    ascending=False)\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Visualizing random forest trees\n",
    "# from sklearn.externals.six import StringIO  \n",
    "# from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "# dot_data = StringIO()\n",
    "export_graphviz(mdl2, out_file='mytree3',  \n",
    "                filled=True, rounded=True,\n",
    "                feature_names=x_train.columns, max_depth=6,proportion=True,rotate=True)\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph.create_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
